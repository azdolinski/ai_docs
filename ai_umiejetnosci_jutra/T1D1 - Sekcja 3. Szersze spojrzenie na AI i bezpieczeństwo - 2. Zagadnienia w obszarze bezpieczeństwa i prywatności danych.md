# Sekcja 3. Szersze spojrzenie na AI i bezpieczeÅ„stwo - 2. Zagadnienia w obszarze bezpieczeÅ„stwa i prywatnoÅ›ci danych

# ğŸ’¡ Diagram

```mermaid
graph TD
    A[DataPrivacyAndSecurityInAI] --> B[Introduction]
    A --> C[FundamentalPrinciples]
    A --> D[HowAIToolsUtilizeData]
    A --> E[RisksOfDataDisclosure]
    A --> F[PracticalTipsForSecurity]
    A --> G[DataResponsibilityProfLife]
    A --> H[SummaryAndKeyActions]

    B --> B1[UnderstandingPrivacy]
    B --> B2[UnderstandingSecurity]

    C --> C1[IsItNecessaryAndSecure]
    C --> C2[DataMinimization]
    C --> C3[SensitiveDataExamples]
    C --> C4[ConsequencesSensitiveData]
    C --> C5[PrivacyPoliciesCredibility]

    C3 --> C3_1[NameLastName]
    C3 --> C3_2[AddressDetails]
    C3 --> C3_3[PhoneNumber]
    C3 --> C3_4[MedicalDocuments]
    C3 --> C3_5[CreditCardNumbers]

    C4 --> C4_1[DataBreaches]
    C4 --> C4_2[UnauthorizedUse]
    C4 --> C4_3[Impersonation]
    C4 --> C4_4[Fraud]

    D --> D1[NoUniversalAnswer]
    D --> D2[PrivacyPolicyGuarantees]
    D --> D3[DataUsageExamples]

    D2 --> D2_1[NoAutoShare]
    D2 --> D2_2[NoTrainingWithoutNotice]

    D3 --> D3_1[QueryProcessing]
    D3 --> D3_2[ImprovingResponseQuality]

    D3_1 --> D3_1_1[SolelyForQuery]
    D3_1 --> D3_1_2[NotPublicDB]
    D3_2 --> D3_2_1[EnhanceQuality]
    D3_2 --> D3_2_2[NoIndividualLink]
    D3_2 --> D3_2_3[NoPublicDB]


    E --> E1[DataTheftBreaches]
    E --> E2[IdentityTheft]
    E --> E3[FinancialFraud]
    E --> E4[DataSecurityParamount]

    F --> F1[ReadPrivacyPolicies]
    F --> F2[UsePrivacySettings]
    F --> F3[AvoidSensitiveData]

    F1 --> F1_1[DataCollectedUsage]
    F1 --> F1_2[GeminiExample]
    F2 --> F2_1[ControlOverData]
    F3 --> F3_1[MinimizePrivateData]
    F3 --> F3_2[UseGenericData]

    G --> G1[SeparatePersonalProfessional]
    G --> G2[BusinessDataRegulations]
    G --> G3[BusinessAISolutions]
    G --> G4[GoogleWorkspacePrivacy]

    G2 --> G2_1[DifferentRules]
    G2 --> G2_2[NotYourProperty]
    G3 --> G3_1[AdvancedRules]
    G3 --> G3_2[GoogleCloudVertexAI]
    G4 --> G4_1[NoShareWithoutConsent]
    G4 --> G4_2[NoTraining]

    H --> H1[SecurityPrivacyCrucial]
    H --> H2[ActivelyProtectData]
    H --> H3[UnderstandDataCollection]
    H --> H4[MinimizeRiskDisclosure]
    H --> H5[SimpleStepsProtection]

    H5 --> H5_1[UpdatePasswords2FA]
    H5 --> H5_2[ReviewPrivacySettingsAI]
    H5 --> H5_3[CompanyAIPolicies]
    H5 --> H5_4[ReviewPrivacyDocs]
    H5 --> H5_5[DeleteHistoricalData]

    H5_4 --> H5_4_1[TermsOfService]

```

___

# ğŸ—’ï¸ Notatka


# Notatki i Podsumowanie Transkrypcji Wideo: "UmiejÄ™tnoÅ›ci Jutra AI" - PrywatnoÅ›Ä‡ i BezpieczeÅ„stwo Danych w AI

## Wprowadzenie do PrywatnoÅ›ci i BezpieczeÅ„stwa w KontekÅ›cie `AI`

This lesson addresses **data privacy and security** within the context of using **artificial intelligence (AI)** tools. We frequently use `AI` in our daily lives, often without considering the data we share and the potential consequences. The aim of this lesson is to clarify how `AI` tools utilize user data and how to ensure its security.

### Understanding Privacy and Security

*   **Privacy**: Your **right to control** how your data is:
    *   Collected
    *   Stored
    *   Used
*   **Security**: Protection of data against:
    *   **Unauthorized access**
    *   **Modification**
    *   **Loss**
    *   Prevention of attacks (e.g., data theft, introduction of malicious data into `AI` systems).

## Fundamental Principles of Data Protection and Privacy in `AI`

### Is It Truly Necessary and Secure?

*   Before entering data into any online tools, including `AI`, ask yourself: **"Is this necessary and secure?"**
*   **`AI` tools are not exempt** â€“ the same data security principles apply.

### Data Minimization

*   **Avoid entering unnecessary data** to obtain results or utilize tool functions.
*   **Pay particular attention to personal and sensitive data**:
    *   First and last name
    *   Address details
    *   Phone number
    *   Medical documents
    *   Credit card numbers

### Consequences of Revealing Sensitive Data

*   **Data breaches**
*   **Unauthorized use**
*   **Impersonation**
*   **Fraud**

### Privacy Policies and Data Usage Rules

*   **Familiarize yourself with privacy policies** if providing data is justified and necessary.
*   **If in doubt about credibility?** â€“ Refrain from using the tool and seek alternatives.

## How `AI` Tools Utilize Input Data

### No Universal Answer

*   **Much depends on the developers of the `AI` application.**
*   **Reviewing privacy policies is crucial.**

### Guarantees in Privacy Policies (Minimum)

*   **User data is not automatically shared with other users.**
*   **`AI` models do not use user data for training without proper notification.**

### Examples of Data Usage

*   **Query Processing**: Entered data (e.g., project description) is used **solely to process your query.**
    *   Stored as part of the interaction with the tool.
    *   **Should not be shared with others or end up in public databases.**
*   **Improving Response Quality**: Responsibly trained `AI` models may use user data **to enhance the quality of responses.**
    *   **Without linking data to individual accounts.**
    *   **Without placing data in databases accessible to others.**

## Risks of Data Disclosure and Consequences

*   **Data theft or breaches** â€“ serious repercussions.
*   **Identity theft**
*   **Financial fraud**
*   **Maintaining data security in `AI` applications is paramount.**

## Practical Tips for Data Security in `AI` Applications

### Read Privacy Policies

*   **Check what data is collected and how it is used** before using an `AI` application.
*   **Example: Gemini (Google)**: Explains data retention periods and user data deletion options (information available in the Gemini privacy center).

### Utilize Appropriate Privacy Settings

*   Privacy-respecting applications provide **complete control over your data.**

### Avoid Entering Sensitive Data

*   **Minimize sharing private data** (email, financial details).
*   **Use generic data** that poses no risk if breached.

## Data Responsibility in Professional Life

### Separating Personal and Professional Digital Spheres

*   **Keep personal and professional digital lives separate.**
*   **Do not use personal accounts and applications for business data.**

### Differences in Regulations and Security Requirements

*   **Business data** may be subject to different regulations, not be your property, and require distinct security and privacy rules.
*   **`AI` solutions for business** may have more sophisticated data collection and processing rules than consumer-grade applications.
*   **Example: Google Cloud Vertex `AI`** â€“ advanced methods for data sovereignty control.

### Privacy of Generative `AI` in Google Workspace

*   **Google Workspace (Gmail, Google Docs, Sheets, Drive, Calendar)**:
    *   Content (emails, documents) **is not shared without consent.**
    *   Applies to Google Workspace products **for personal and business use.**
    *   **Data remains within Workspace and is not used for training or improving generative `AI`.**

## Summary and Key Actions

### Security and Privacy are Crucial in `AI`

*   **Actively protect your data** as users.
*   **Understand how `AI` tools collect and use data.**
*   **Minimize the risk of losing control and unwanted data disclosure.**

### Simple and Quick Steps for Enhanced Data Protection

*   **Update passwords and enable two-factor authentication.**
    *   **Protecting digital identity is a priority.**
*   **Review privacy settings in `AI` applications and disable unnecessary data collection features.**
*   **Learn about your company's `AI` policies and adhere to them.**
*   **Review privacy documentation before using new `AI` tools.**
    *   **Familiarize yourself with the privacy policy and terms of service.**
    *   **Understand what data is collected and how it is used.**
*   **Regularly delete historical data.**
    *   **In the data management section of `AI` applications, remove unnecessary conversations, data, and activities.**
    *   **Limit the amount of information stored about you.**

## Transcription Summary

The video transcription "UmiejÄ™tnoÅ›ci Jutra `AI`" addresses critical aspects of **data privacy and security in the context of artificial intelligence tools**. The speaker clarifies the definitions of privacy and security, emphasizing the user's right to control their data and the necessity of its protection.

A key point is **data minimization** when entering information into `AI` tools, especially sensitive data. The **importance of reading privacy policies** and **verifying the credibility of `AI` application providers** is highlighted.

The transcription explains that **data usage by `AI` depends on application developers**, but privacy policies should guarantee that data is not automatically shared with other users and is not used for training `AI` models without notification. Data may be used for query processing and improving response quality, while adhering to privacy principles.

The risks of **data breaches and serious consequences**, such as identity theft, are pointed out. **Practical tips for data protection** are presented: reading privacy policies, using privacy settings, and avoiding sensitive data.

The **difference in data responsibility in personal and professional life** is emphasized, recommending the separation of these digital spheres and the use of appropriate solutions (e.g., Google Workspace for business with privacy assurances).

Finally, the speaker lists **simple actions** to strengthen data security, such as updating passwords, verifying privacy settings, understanding privacy policies, and regularly deleting historical data.

The main message is to **actively care for data privacy and security** in the `AI` era by consciously using tools, reading privacy policies, and applying data minimization principles.


___

# ğŸ”‰ Transcript
File: Sekcja 3. Szersze spojrzenie na AI i bezpieczeÅ„stwo - 2. Zagadnienia w obszarze bezpieczeÅ„stwa i prywatnoÅ›ci danych.mp4<br>
[00:00:04] (The screen shows a slide with the title "UmiejÄ™tnoÅ›ci Jutra AI". Below this, there are three logos: Google, SGH, and Minister Cyfryzacji.)
[00:00:05] Speaker: Na co dzieÅ„ korzystamy z narzÄ™dzie AI, ale czÄ™sto nie zastanawiamy siÄ™, jakie dane udostÄ™pniamy i jakie mogÄ… byÄ‡ tego konsekwencje.
[00:00:12] (The speaker's face is shown in a closer shot.)
[00:00:13] Speaker: W tej lekcji dowiesz siÄ™, jak narzÄ™dzie AI wykorzystujÄ… dane, ktÃ³re wprowadzamy i jak dbaÄ‡ o swoje dane w tych aplikacjach.
[00:00:21] Speaker: Zacznijmy od tego, czym tak wÅ‚aÅ›ciwie jest prywatnoÅ›Ä‡ i bezpieczeÅ„stwo.
[00:00:25] Speaker: PrywatnoÅ›Ä‡ to twoje prawo do kontroli nad tym, jak twoje dane sÄ… zbierane, przechowywane i wykorzystywane.
[00:00:33] Speaker: Gdy korzystasz z aplikacji AI, wprowadzasz dane, ktÃ³re mogÄ… obejmowaÄ‡ twoje imiÄ™, lokalizacjÄ™, historiÄ™ wyszukiwania czy preferencje.
[00:00:41] Speaker: BezpieczeÅ„stwo oznacza ochronÄ™ tych danych przed nieautoryzowanym dostÄ™pem, modyfikacjÄ… lub utratÄ….
[00:00:47] Speaker: To takÅ¼e zapobieganie atakom, jak na przykÅ‚ad kradzieÅ¼ danych czy wprowadzenie szkodliwych danych do systemÃ³w AI.
[00:00:55] Speaker: Dobrze, przejdÅºmy teraz do podstawowych zasad, o ktÃ³rych powinniÅ›my pamiÄ™taÄ‡, chcÄ…c chroniÄ‡ nasze dane i ich prywatnoÅ›Ä‡.
[00:01:02] Speaker: Po pierwsze, wprowadzajÄ…c dane do jakichkolwiek narzÄ™dzi udostÄ™pnianych w internecie, powinniÅ›cie zadaÄ‡ sobie pytanie, czy jest to na pewno konieczne i czy jest to bezpieczne.
[00:01:13] Speaker: NarzÄ™dzia sztucznej inteligencji nie stanowiÄ… tutaj wyjÄ…tku.
[00:01:17] Speaker: Nie wprowadzajcie Å¼adnych danych, ktÃ³re nie sÄ… niezbÄ™dne do uzyskania poÅ¼Ä…danego wyniku czy skorzystania z danej funkcjonalnoÅ›ci narzÄ™dzia.
[00:01:25] Speaker: Zachowajcie szczegÃ³lnÄ… uwagÄ™ w przypadku danych osobowych i innych danych wraÅ¼liwych, takich jak na przykÅ‚ad imiÄ™, nazwisko, dane adresowe, numer telefonu, dokumenty medyczne i numery kart kredytowych.
[00:01:39] Speaker: Dlaczego?
[00:01:40] Speaker: PoniewaÅ¼ z pewnoÅ›ciÄ… nie chcielibyÅ›cie, aby te dane zostaÅ‚y ujawnione w wycieku lub wykorzystane w innym nieautoryzowany przez was sposÃ³b, w tym do podszywania siÄ™ pod was, czy do innego rodzaju oszustwa.
[00:01:52] Speaker: A co jeÅ¼eli podanie takich danych jest uzasadnione i konieczne?
[00:01:56] Speaker: Takie sytuacje mogÄ… siÄ™ oczywiÅ›cie zdarzyÄ‡.
[00:01:59] Speaker: Wtedy koniecznie zapoznajcie siÄ™ z politykami prywatnoÅ›ci i zasadami wykorzystywania waszych danych.
[00:02:05] Speaker: JeÅ¼eli macie jakiekolwiek wÄ…tpliwoÅ›ci co do wiarygodnoÅ›ci autorÃ³w aplikacji lub treÅ›ci tych polityk, zrezygnujcie z wykorzystania ich i poszukajcie alternatywnego rozwiÄ…zania.
[00:02:16] Speaker: Teraz moÅ¼emy zadaÄ‡ sobie pytanie, jak w takim razie narzÄ™dzia AI wykorzystujÄ… dane, ktÃ³re wprowadzamy.
[00:02:23] Speaker: Wiele osÃ³b zastanawia siÄ™, czy jeÅ›li wprowadzÄ… jakÄ…Å› informacjÄ™ do narzÄ™dzia opartego na AI, ta sama informacja pojawi siÄ™ pÃ³Åºniej, gdy ktoÅ› inny bÄ™dzie szukaÅ‚ podobnych odpowiedzi.
[00:02:34] Speaker: To zrozumiaÅ‚e.
[00:02:35] Speaker: W dobie cyfrowych technologii nie zawsze Å‚atwo jest zrozumieÄ‡, co dzieje siÄ™ z naszymi danymi po ich wprowadzeniu.
[00:02:42] Speaker: Niestety, nie ma na to pytanie uniwersalnej odpowiedzi.
[00:02:45] Speaker: Wiele zaleÅ¼y od twÃ³rcÃ³w aplikacji.
[00:02:48] Speaker: WÅ‚aÅ›nie dlatego powinniÅ›my zapoznaÄ‡ siÄ™ z politykami prywatnoÅ›ci, obowiÄ…zujÄ…cymi w stosunku do wykorzystywanych przez nas narzÄ™dzi.
[00:02:56] Speaker: To, co dzieje siÄ™ z naszymi danymi, powinno byÄ‡ w nich dokÅ‚adnie opisane.
[00:03:01] Speaker: Zasady prywatnoÅ›ci powinny gwarantowaÄ‡ uÅ¼ytkownikom co najmniej, Å¼e ich dane nie sÄ… automatycznie udostÄ™pniane innym uÅ¼ytkownikom.
[00:03:10] Speaker: A modele AI, ktÃ³re sÄ… trenowane na okreÅ›lonych zbiorach danych, nie wykorzystujÄ… do tego danych uÅ¼ytkownikÃ³w bez udostÄ™pnienia im odpowiedniej informacji na ten temat.
[00:03:20] Speaker: Co to znaczy?
[00:03:22] Speaker: Po pierwsze, jeÅ›li wprowadzisz jakÄ…Å› informacjÄ™ do narzÄ™dzia AI, na przykÅ‚ad opis projektu lub preferencje, te dane bÄ™dÄ… uÅ¼ywane tylko do przetwarzania twojego zapytania.
[00:03:33] Speaker: Powinny byÄ‡ przechowywane w ramach twojej interakcji z narzÄ™dziem AI i nie powinny byÄ‡ udostÄ™pniane innym osobom, ani trafiaÄ‡ do publicznych baz danych.
[00:03:42] Speaker: Po drugie, odpowiedzialnie trenowane modele AI mogÄ… zgodnie z politykÄ… prywatnoÅ›ci korzystaÄ‡ z danych uÅ¼ytkownikÃ³w, na przykÅ‚ad do ulepszania jakoÅ›ci odpowiedzi, ale bez Å‚Ä…czenia ich z indywidualnym kontem czy umieszczania w bazach danych dostÄ™pnych dla innych.
[00:04:00] Speaker: Warto pamiÄ™taÄ‡, Å¼e nasze dane, jeÅ›li nie sÄ… odpowiednio chronione, mogÄ… zostaÄ‡ ujawnione na skutek kradzieÅ¼y lub wycieku.
[00:04:08] Speaker: Jak juÅ¼ wspominaÅ‚em, moÅ¼e to prowadziÄ‡ do powaÅ¼nych konsekwencji, takich jak kradzieÅ¼ toÅ¼samoÅ›ci czy naduÅ¼ycia finansowe.
[00:04:16] Speaker: Dlatego dbanie o bezpieczeÅ„stwo danych w aplikacjach AI jest kluczowe.
[00:04:21] Speaker: Co moÅ¼ecie zrobiÄ‡ w tym zakresie?
[00:04:23] Speaker: Jak mogliÅ›cie juÅ¼ usÅ‚yszeÄ‡, czytajcie polityki prywatnoÅ›ci.
[00:04:27] Speaker: Przed uÅ¼yciem jakiejkolwiek aplikacji AI sprawdÅºcie jakie dane sÄ… przez niÄ… zbierane i jak sÄ… wykorzystywane.
[00:04:34] Speaker: PrzykÅ‚adowo w aplikacjach takich jak Gemini Google wyjaÅ›nia, Å¼e przechowuje dane przez okreÅ›lony czas i pozwala na ich usuwanie.
[00:04:43] Speaker: W prosty sposÃ³b moÅ¼ecie zapoznaÄ‡ siÄ™ z tymi informacjami w centrum prywatnoÅ›ci dotyczÄ…cymi aplikacji z Gemini.
[00:04:50] Speaker: Kolejna wskazÃ³wka to uÅ¼ywajcie odpowiednich ustawieÅ„ prywatnoÅ›ci.
[00:04:55] Speaker: PamiÄ™tajcie, Å¼e aplikacje stworzone z poszanowaniem prywatnoÅ›ci danych pozwalajÄ… wam na peÅ‚nÄ… kontrolÄ™ nad tym, co siÄ™ dzieje z waszymi danymi.
[00:05:04] Speaker: I w koÅ„cu unikajcie wprowadzania danych wraÅ¼liwych.
[00:05:08] Speaker: Przekazywanie prywatnych danych, takich jak adresy email czy dane finansowe powinno byÄ‡ ograniczone do minimum.
[00:05:15] Speaker: Zamiast tego uÅ¼ywajcie ogÃ³lnych danych, ktÃ³re w przypadku wycieku nie stanowiÄ… zagroÅ¼enia.
[00:05:20] Speaker: PrzejdÅºmy teraz do kolejnego aspektu zwiÄ…zanego bardziej z naszym Å¼yciem zawodowym.
[00:05:25] Speaker: OdpowiedzialnoÅ›Ä‡ za dane i bezpieczeÅ„stwo moÅ¼e bowiem wyglÄ…daÄ‡ inaczej, w zaleÅ¼noÅ›ci od tego, czy jesteÅ› konsumentem, czy reprezentujesz przedsiÄ™biorstwo.
[00:05:35] Speaker: TakÅ¼e w przypadku rozwiÄ…zaÅ„ AI warto trzymaÄ‡ siÄ™ ogÃ³lnie obowiÄ…zujÄ…cej zasady.
[00:05:41] Speaker: W sferze cyfrowej nie mieszaÄ‡ ze sobÄ… Å¼ycia prywatnego i zawodowego, w szczegÃ³lnoÅ›ci nie wykorzystywaÄ‡ kont prywatnych i powiÄ…zanych z nimi aplikacji do przetwarzania danych biznesowych.
[00:05:53] Speaker: Dlaczego?
[00:05:53] Speaker: Dane biznesowe mogÄ… podlegaÄ‡ zupeÅ‚nie innym regulacjÄ…, nie stanowiÄ‡ twojej wÅ‚asnoÅ›ci i wymagaÄ‡ innych zasad bezpieczeÅ„stwa i prywatnoÅ›ci niÅ¼ dane prywatne.
[00:06:04] Speaker: W szczegÃ³lnoÅ›ci rozwiÄ…zania AI przeznaczone do zastosowaÅ„ biznesowych mogÄ… posiadaÄ‡ inne zasady gromadzenia i przetwarzania danych, zwykle bardziej zaawansowane niÅ¼ rozwiÄ…zania konsumenckie.
[00:06:16] Speaker: PrzykÅ‚adem moÅ¼e byÄ‡ rozwiÄ…zanie Google Cloud Vertex AI, obejmujÄ…ce zaawansowane metody kontroli suwerennoÅ›ci danych.
[00:06:23] Speaker: Aby zrozumieÄ‡ tÄ™ rÃ³Å¼nicÄ™, skupmy siÄ™ na chwilÄ™ na zasadach prywatnoÅ›ci dotyczÄ…cych generatywnej AI w Google Workspace.
[00:06:32] Speaker: ZaprojektowaliÅ›my naszÄ… technologiÄ™ w taki sposÃ³b, aby treÅ›ci, takie jak maile czy dokumenty, nie byÅ‚y udostÄ™pniane innym bez twojej zgody.
[00:06:41] Speaker: To zobowiÄ…zanie dotyczy wszystkich produktÃ³w Google Workspace do uÅ¼ytku osobistego i biznesowego, w tym Gmail, dokumenty Google, arkusze, dysk, kalendarz i inne rozwiÄ…zania z pakietu.
[00:06:54] Speaker: Twoje dane pozostajÄ… w Workspace i nie sÄ… wykorzystywane do trenowania ani ulepszania generatywnej AI, w tym duÅ¼ych modeli jÄ™zykowych.
[00:07:04] Speaker: PodsumowujÄ…c, takÅ¼e w kontekÅ›cie narzÄ™dzi AI, bezpieczeÅ„stwo i prywatnoÅ›Ä‡ sÄ… kluczowe.
[00:07:09] Speaker: Jako uÅ¼ytkownicy musimy aktywnie dbaÄ‡ o nasze dane, rozumiejÄ…c jak narzÄ™dzia zbierajÄ… informacjÄ™, jak je wykorzystujÄ… i jak moÅ¼emy zminimalizowaÄ‡ ryzyko utraty kontroli, w szczegÃ³lnoÅ›ci niepoÅ¼Ä…danego ujawnienia danych.
[00:07:25] Speaker: Na koniec, kilka prostych i szybkich dziaÅ‚aÅ„, ktÃ³re moÅ¼esz podjÄ…Ä‡, by zaczÄ…Ä‡ lepiej chroniÄ‡ swoje dane.
[00:07:31] Speaker: Zaktualizuj swoje hasÅ‚a i wÅ‚Ä…cz weryfikacjÄ™ dwuetapowÄ….
[00:07:36] Speaker: Ochrona cyfrowej toÅ¼samoÅ›ci to zawsze powinien byÄ‡ twÃ³j numer jeden.
[00:07:41] Speaker: SprawdÅº ustawienia prywatnoÅ›ci w aplikacjach AI, z ktÃ³rych korzystasz i wyÅ‚Ä…cz funkcje, ktÃ³re mogÄ… zbieraÄ‡ niepotrzebne dane.
[00:07:50] Speaker: Dowiedz siÄ™, jakie sÄ… zasady stosowania rozwiÄ…zaÅ„ AI w twojej firmie i dostosuj siÄ™ do nich.
[00:07:56] Speaker: Przejrzyj dokumentacjÄ™ prywatnoÅ›ci.
[00:07:59] Speaker: Zanim zaczniesz korzystaÄ‡ z nowych narzÄ™dzi AI, zapoznaj siÄ™ z politykÄ… prywatnoÅ›ci dostawcy i warunkami uÅ¼ytkowania.
[00:08:06] Speaker: Dowiedz siÄ™, jakie dane sÄ… zbierane i w jaki sposÃ³b sÄ… wykorzystywane.
[00:08:11] Speaker: Usuwaj regularnie historyczne dane.
[00:08:14] Speaker: JeÅ›li korzystasz z aplikacji AI, przejdÅº do sekcji zarzÄ…dzania danymi i usuÅ„ rozmowy, dane lub aktywnoÅ›ci, ktÃ³re sÄ… zbÄ™dne.
[00:08:23] Speaker: DziaÅ‚ajÄ…c w ten sposÃ³b, ograniczysz iloÅ›Ä‡ przechowywanych informacji o tobie.
[00:08:28] (The screen shows a slide with the title "UmiejÄ™tnoÅ›ci Jutra AI". Below this, there are three logos: Google, SGH, and Minister Cyfryzacji.)

___
# ğŸ·ï¸ Tags
#AI #artificial_intelligence #data_privacy #data_security #privacy #security #data_protection #data_minimization #sensitive_data #personal_data #privacy_policies #data_usage #AI_models #query_processing #response_quality #data_breaches #identity_theft #financial_fraud #privacy_settings #generic_data #professional_life #digital_spheres #business_data #regulations #security_requirements #Google_Cloud_Vertex_AI #Google_Workspace #Gmail #Google_Docs #Sheets #Drive #Calendar #two-factor_authentication #digital_identity #AI_policies #terms_of_service #data_management #historical_data #data_disclosure #unauthorized_access #data_theft #malicious_data #data_sovereignty #generative_AI #data_control #data_collection #data_storage #data_usage_rules #data_responsibility
